{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Notebook ~ By: Samuel Escalante Gutierrez\n",
    "This Jupyter Notebook demonstrates the data processing workflow using the `TransformData` class from the `transform_data.py` module and load final data into 'SuccessfulApplicants' table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is where our Notebook begin  \n",
    "\n",
    "Appends a directory path to the Python system path, be sure replace de path for your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "work_dir = os.getenv('WORK_DIR')\n",
    "\n",
    "sys.path.append(work_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_operations.transform_data import TransformData\n",
    "from sqlalchemy import  inspect\n",
    "from src.models.DatabaseModels import SuccessfulApplicants\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "import pandas as pd\n",
    "from src.database.db_connection import get_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conected successfully to database Workshop-1!\n"
     ]
    }
   ],
   "source": [
    "connection = get_engine()\n",
    "\n",
    "BASE = declarative_base()  \n",
    "\n",
    "Session = sessionmaker(bind=connection)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation and Merge Explanation\n",
    "\n",
    "The following code snippet demonstrates the process of transforming data using the `TransformData` class and merging two DataFrames.\n",
    "\n",
    "#### 1. Creating Instances of TransformData\n",
    "#### 2. Applying Transformations to the Candidates DataFrame  \n",
    "- Including renaming columns, inserting an 'id' column, grouping by category, and adding a 'Hired' column based on specified conditions.\n",
    "\n",
    "**Grouping by category has this structure:**\n",
    "- **Development:**\n",
    "    - _'Development - CMS Backend'_\n",
    "    - _'Development - CMS Frontend'_\n",
    "    - _'Development - FullStack'_\n",
    "    - _'Development - Frontend'_\n",
    "    - _'Development - Backend'_\n",
    "    - _'Game Development'_\n",
    "    - _'DevOps'_\n",
    "    - _'Adobe Experience Manager'_\n",
    "\n",
    "- **Quality Assurance:**\n",
    "    - _'QA Automation'_\n",
    "    - _'QA Manual'_\n",
    "\n",
    "- **Security:**\n",
    "    - _'System Administration'_\n",
    "    - _'Security Compliance'_\n",
    "    - _'Security'_\n",
    "\n",
    "- **Data & Analytics:**\n",
    "    - _'Database Administration'_\n",
    "    - _'Data Engineer'_\n",
    "    - _'Business Intelligence'_\n",
    "    - _'Business Analytics / Project Management'_\n",
    "\n",
    "- **Sales and Business:**\n",
    "    - _'Salesforce'_\n",
    "    - _'Sales'_\n",
    "    - _'Client Success'_\n",
    "\n",
    "- **Marketing and Communication:**\n",
    "    - _'Social Media Community Management'_\n",
    "    - _'Mulesoft'_\n",
    "    - _'Technical Writing'_\n",
    "\n",
    "- **Design:**\n",
    "    - _'Design'_\n",
    "\n",
    "#### 3. Accessing DataFrames within Instances\n",
    "#### 4. Additional Transformations and Merge\n",
    "#### 5. Final DataFrame Order and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "transformer_country = TransformData('../data/countries-continent.csv')\n",
    "transformer_candidates = TransformData('../data/candidates.csv')\n",
    "\n",
    "# 2.\n",
    "transformer_candidates.rename_columns()\n",
    "transformer_candidates.insertar_id()\n",
    "transformer_candidates.group_by_category()\n",
    "transformer_candidates.agregar_contratados()\n",
    "\n",
    "# 3.\n",
    "df_country = transformer_country.df\n",
    "df_candidates = transformer_candidates.df\n",
    "\n",
    "# 4.\n",
    "df_candidates['ApplicationDate'] = pd.to_datetime(df_candidates['ApplicationDate'])\n",
    "\n",
    "# 5.\n",
    "df_merged = pd.merge(df_country, df_candidates, on=\"Country\", how=\"inner\")\n",
    "\n",
    "column_order = ['id','FirstName', 'LastName', 'Email', 'ApplicationDate', 'Country', 'Continent', 'YOE', 'Seniority', 'Technology', 'CodeChallengeScore', 'TechnicalInterviewScore','CategoryOfTechnology', 'Hired']\n",
    "df_merged = df_merged[column_order]\n",
    "\n",
    "df_merged.to_csv('../data/SuccessfulApplicants.csv', sep=';', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first checks if the 'SuccessfulApplicants' table already exists in the database before attempting to delete and recreate it. An `if-else` conditional structure is used to handle both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "if inspect(connection).has_table('SuccessfulApplicants'):\n",
    "    try:\n",
    "        SuccessfulApplicants.__table__.drop(connection)\n",
    "        SuccessfulApplicants.__table__.create(connection)\n",
    "        print(\"Table created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table {e}\")\n",
    "else:\n",
    "    try:\n",
    "        SuccessfulApplicants.__table__.create(connection)\n",
    "        print(\"Table created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from a CSV file to a table called 'SuccessfulApplicants' in the database. A `try-except-finally` block is used to handle data loading and ensure that the session is closed correctly upon completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    file = TransformData('../data/SuccessfulApplicants.csv')\n",
    "\n",
    "    file.df.to_sql('SuccessfulApplicants', connection, if_exists='replace', index=False)\n",
    "    print(\"Data uploaded\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
